{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgesc-05/clase-inteligencia-artificial/blob/main/Fundamento_Cuaderno_15_XGBOOST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"red\">Cuaderno 15. XGBOOST</font>\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting) es una implementación avanzada del algoritmo de Gradient Boosting, vamos en este cuarderno a explicar los conceptos básicos y la implementacicóm del modelo de machine learning. Este es ampliamente utilizada en problemas de clasificación y regresión debido a su capacidad para lograr un alto rendimiento en competiciones y aplicaciones del mundo real, wa eficiente, flexible y rápido, mejorando el rendimiento del aprendizaje en comparación con otras implementaciones de Gradient Boosting como las de Scikit-learn.\n",
        "\n",
        "![imagen](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nD4DibWC56hwhyrc.png)\n",
        "\n",
        "En la imagen observamos cómo se construyen los árboles y cada uno de manera individual crean un clasificador \"classifier 1,2, .., n) y luego se ensamblan los modelos. La gran diferencia con respecto a Bosques Aleoatorios es que cada arbol aprende de su antecesor y no son \"aleatorios\".\n",
        "\n",
        "## <font color=\"red\">15.1 Definciones de Gradient Boosting</font>\n",
        "Gradient Boosting es un método de aprendizaje en equipo (ensemble learning) que construye un modelo robusto combinando múltiples modelos débiles (generalmente árboles de decisión) de manera secuencial. La idea clave es que cada nuevo modelo se construye para corregir los errores cometidos por los modelos anteriores.\n",
        "* ***Modelos débiles:*** En Gradient Boosting, los modelos base son usualmente árboles de decisión con poca profundidad.\n",
        "* Corrección de errores: En cada iteración, se entrena un nuevo modelo para minimizar el error residual del modelo anterior.\n",
        "* ***Agregación:*** Los resultados de todos los modelos se combinan para hacer la predicción final.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">15.2 Diferencia entre otros modelos</font>\n",
        "XGBoost es una implementación optimizada y mejorada de Gradient Boosting que incorpora características avanzadas para superar limitaciones comunes. Sus principales diferencias incluyen:\n",
        "\n",
        "* ***Optimización del rendimiento:***\n",
        "  * Implementa algoritmos altamente eficientes para la construcción de árboles.\n",
        "  * Utiliza técnicas como shrinkage (reducción de la tasa de aprendizaje) y feature subsampling (submuestreo de características) para evitar el sobreajuste.\n",
        "* ***Regularización:***\n",
        "  * XGBoost incluye regularización L1L1L1 y L2L2L2 para penalizar la complejidad del modelo y evitar el sobreajuste, lo que lo hace más robusto que las implementaciones estándar de Gradient Boosting.\n",
        "* ***Paralelismo:***\n",
        "  * Implementa paralelismo a nivel de características, lo que reduce significativamente el tiempo de entrenamiento en comparación con otros métodos de Boosting.\n",
        "* ***Capacidad de manejo de valores nulos:***\n",
        "  * XGBoost puede manejar datos con valores faltantes de manera eficiente, ya que durante la construcción de los árboles aprende automáticamente cómo dividir las muestras faltantes.\n",
        "* ***Escalabilidad:***\n",
        "  * Puede manejar conjuntos de datos muy grandes y problemas de alta dimensionalidad debido a su diseño eficiente en memoria.\n",
        "* ***Objetivos personalizables:***\n",
        "  * Permite usar funciones de pérdida personalizadas, lo que lo hace flexible para adaptarse a una amplia gama de problemas.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=\"red\">15.3 Funcionamiento Interno de XGBoost</font>\n",
        "El proceso de XGBoost se basa en los siguientes pasos:\n",
        "* ***Inicialización:***\n",
        "  * Se predice un valor inicial (como la media en problemas de regresión o la proporción de la clase positiva en clasificación).\n",
        "* ***Construcción de modelos:***\n",
        "  * En cada iteración, XGBoost construye un árbol de decisión utilizando el gradiente de la función de pérdida para ajustar las predicciones y minimizar el error.\n",
        "* ***Actualización:***\n",
        "  * Los nuevos árboles corrigen los errores residuales de los árboles anteriores.\n",
        "* ***Combinación de modelos:***\n",
        "  * Los árboles entrenados se combinan usando pesos (generalmente controlados por la tasa de aprendizaje o learning rate).\n",
        "* ***Regularización:***\n",
        "  * Se penaliza la complejidad del modelo mediante regularización para reducir el riesgo de sobreajuste.\n",
        "\n",
        "\n",
        "La función objetivo que optimiza XGBoost incluye dos términos:\n",
        "\n",
        "$Obj(\\theta) = \\sum_{i=1}^n L(y_i, \\hat{y}_i) + \\sum_{j=1}^k \\Omega(f_j)$\n",
        "\n",
        "\n",
        "\n",
        "Donde:\n",
        "* L: Es la función de pérdida (por ejemplo, error cuadrático para regresión o\n",
        "$log-loss$ para clasificación).\n",
        "* $\\Omega(f_j)$: Es un término de regularización para controlar la complejidad de los árboles.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">15.4 Ventajas de XGBoost</font>\n",
        "* Alto rendimiento:\n",
        "  * Funciona muy bien con datos estructurados/tabulares y es el algoritmo favorito en competencias como Kaggle.\n",
        "* Flexibilidad:\n",
        "  * Permite configurar varios parámetros para personalizar el comportamiento del modelo.\n",
        "* Soporte para clasificación y regresión:\n",
        "  * Es versátil y puede aplicarse a problemas de regresión, clasificación binaria y multiclase.\n",
        "* Velocidad:\n",
        "  * Su optimización lo hace mucho más rápido que Gradient Boosting estándar.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">15.5 Desventajas de XGBoost</font>\n",
        "* Mayor complejidad:\n",
        "  * Requiere más experiencia y ajuste de parámetros en comparación con modelos más simples como Random Forest.\n",
        "* Riesgo de sobreajuste:\n",
        "  * Aunque incorpora regularización, aún puede sobreajustarse si no se configuran correctamente los hiperparámetros.\n",
        "* No tan bueno para datos no estructurados:\n",
        "  * En tareas como imágenes o texto, los modelos basados en redes neuronales (como CNNs y transformers) suelen ser más efectivos.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=\"red\">15.6 Comparación: XGBoost vs. Random Forest</font>\n",
        "\n",
        "| **Aspecto**               | **XGBoost**                                     | **Random Forest**                                |\n",
        "|----------------------------|-------------------------------------------------|-------------------------------------------------|\n",
        "| **Estrategia de aprendizaje** | Boosting (secuencial, modelos corrigen errores previos). | Bagging (paralelo, promedio de modelos independientes). |\n",
        "| **Velocidad de predicción** | Más lento debido al enfoque secuencial.        | Más rápido debido al paralelismo.               |\n",
        "| **Evitar sobreajuste**      | Regularización explícita ($L_1$, $L_2$).       | Promediado de múltiples árboles.                |\n",
        "| **Precisión**               | Más preciso en datos estructurados.            | Menos preciso que XGBoost en general.           |\n",
        "| **Manejo de valores nulos** | Se detectan automáticamente.                   | No tiene soporte automático, requiere preprocesamiento. |\n",
        "| **Eficiencia computacional**| Optimizado con paralelismo.                    | Menos eficiente.                                |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">15.7 Bootstrapping</font>\n",
        "El término Bootstrapping proviene de la expresión en inglés \"pulling yourself up by your bootstraps o hacer las cosas por su cuenta.\", que sugiere hacer algo sin ayuda externa. En el contexto del aprendizaje automático y estadísticas, hace referencia a una técnica que permite crear múltiples conjuntos de datos de entrenamiento a partir de un solo conjunto de datos original, mediante la muestra aleatoria con reemplazo.\n",
        "\n",
        "![imagen](https://media.geeksforgeeks.org/wp-content/uploads/20210707140911/Boosting.png)\n",
        "\n",
        "###¿Cómo funciona?\n",
        "En la imagen anterior se aprecian los siguientes pasos:\n",
        "* Creación de subconjuntos de entrenamiento:\n",
        "  * Se toma el conjunto de datos original y, usando bootstrapping, se generan varios subconjuntos aleatorios de datos (con reemplazo). Cada subconjunto tiene el mismo tamaño que el conjunto original, pero algunos puntos de datos pueden repetirse y otros pueden no aparecer.\n",
        "* Entrenamiento de modelos:\n",
        "  * Para cada subconjunto generado, se entrena un modelo independiente. Estos modelos son entrenados de forma paralela y son \"débiles\" individualmente, es decir, tienen cierta capacidad de generalización, pero no son perfectos.\n",
        "* Predicción:\n",
        "  * Para la predicción de un nuevo dato, se realizan predicciones con cada uno de los modelos entrenados. La salida final es el resultado del promedio (en el caso de regresión) o de la votación mayoritaria (en el caso de clasificación) entre los modelos.\n",
        "\n",
        "###¿Para qué se usa?\n",
        "El bootstrapping se utiliza comúnmente en métodos de ensamble como el bagging y en la estimación de intervalos de confianza, ya que permite obtener estimaciones de los parámetros sin hacer suposiciones muy estrictas sobre la distribución de los datos.\n",
        "\n",
        "### <font color=\"blue\">15.7.1 Bagging (Bootstrap Aggregating)</font>\n",
        "El Bagging es una técnica de ensamble que utiliza bootstrapping para crear varios modelos de aprendizaje, con el fin de reducir la varianza del modelo final y mejorar la precisión del mismo. El algoritmo más comúnmente asociado con bagging es el Árbol de Decisión, aunque también puede aplicarse a otros modelos como SVM, KNN, entre otros.\n",
        "\n",
        "\n",
        "### Diferencia clave entre Bagging y Bootstrapping:\n",
        "* Bootstrapping es la técnica que permite crear muestras aleatorias con reemplazo a partir de un conjunto de datos. Es más una técnica de re-muestreo que una técnica de modelado.\n",
        "* Bagging es un método que utiliza bootstrapping para entrenar múltiples modelos y combinar sus resultados, con el objetivo de mejorar el rendimiento de los modelos.\n",
        "\n",
        "### Visualización rápida:\n",
        "* Bootstrapping: Genera subconjuntos de datos a partir del conjunto original.\n",
        "* Bagging: Utiliza esos subconjuntos para entrenar varios modelos y promedia sus predicciones.\n",
        "\n",
        "\n",
        "### Beneficios del Bagging:\n",
        "* Reducción de varianza: Al combinar múltiples modelos, las predicciones finales son menos susceptibles a la varianza de los datos.\n",
        "* Mejora de la estabilidad: Los modelos individuales pueden ser muy sensibles a los datos, pero el bagging mitiga esto combinando sus salidas.\n",
        "\n",
        "### <font color=\"blue\">15.7.2 Modelos Ensamblados (Ensemble Models)</font>\n",
        "\n",
        "\n",
        "![imagen](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3ByacanwDwnH20OY.png)\n",
        "\n",
        "Como se muesta en la imagen, Un modelo ensamblado es una técnica que combina varias predicciones de diferentes modelos (aggregating) para obtener una única predicción final (Bagging). La idea central detrás de los modelos ensamblados es que varios modelos \"débiles\" (independientes y con un rendimiento regular) pueden combinar sus fortalezas para crear un modelo \"fuerte\" que generaliza mejor en los datos.\n",
        "\n",
        "Los modelos ensamblados pueden mejorar la precisión, reducir el sobreajuste (overfitting) y hacer que el modelo sea más robusto frente a los errores.\n",
        "\n",
        "Existen varias técnicas de ensamblaje, siendo las más comunes:\n",
        "\n",
        "* ***Bagging (Bootstrap Aggregating):** Ya lo mencionamos antes, donde varios modelos son entrenados en subconjuntos diferentes del conjunto de datos y sus predicciones se combinan para obtener una predicción final (votación o promedio).\n",
        "* ***Boosting:*** A diferencia de bagging, en boosting los modelos se entrenan de manera secuencial. Cada modelo intenta corregir los errores del anterior. Esto suele dar lugar a modelos con mayor precisión, pero con un mayor riesgo de sobreajuste si no se controla adecuadamente.\n",
        "\n",
        "* ***Stacking:*** En stacking, se entrenan varios modelos base (o \"primer nivel\") y sus salidas se combinan en un modelo meta (o \"segundo nivel\") que aprenderá a predecir la salida final. Es una combinación de varios modelos que buscan aprender de diferentes aspectos de los datos.\n",
        "\n"
      ],
      "metadata": {
        "id": "UT41BUrGs56G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">10.4  Clasificación de pacientes con Diabetes usando con XGBoosting"
      ],
      "metadata": {
        "id": "h1xxgqLM06Nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo:\n",
        "Vamos a usar  el mismo ejemplo de Bosques Aletorios para que compares los resultldos. Asi este modelo permite  predecir si un paciente tiene diabetes, basado en características como la glucosa, la presión arterial, el IMC, la edad, etc.\n",
        "\n",
        "Pasos para el ejercicio:\n",
        "1. Cargar los datos: Usamos pandas para cargar los datos directamente desde el archivo CSV en GitHub."
      ],
      "metadata": {
        "id": "xqx4FeVU1lD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Cargar el dataset desde el enlace proporcionado en GitHub\n",
        "url = 'https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/diabetes.csv'\n",
        "df = pd.read_csv(url, sep=';')  # El separador es ';' según la muestra proporcionada\n",
        "\n",
        "# Mostrar las primeras filas del dataset\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A9Lbw1sB1xqb",
        "outputId": "8e0f0bea-2135-4c8d-c064-5440f3dd8b8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Embarazos  Glucosa  PresiónArterial  GrosorDeLaPiel  Insulina   IMC  \\\n",
              "0          6      148               72              35         0  33.6   \n",
              "1          1       85               66              29         0  26.6   \n",
              "2          8      183               64               0         0  23.3   \n",
              "3          1       89               66              23        94  28.1   \n",
              "4          0      137               40              35       168  43.1   \n",
              "\n",
              "   FunciónPedigríDeDiabetes  Edad  Resultad  \n",
              "0                     0.627    50         1  \n",
              "1                     0.351    31         0  \n",
              "2                     0.672    32         1  \n",
              "3                     0.167    21         0  \n",
              "4                     2.288    33         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6fa73d6-fc16-48b3-92f5-824d9b6eaf50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Embarazos</th>\n",
              "      <th>Glucosa</th>\n",
              "      <th>PresiónArterial</th>\n",
              "      <th>GrosorDeLaPiel</th>\n",
              "      <th>Insulina</th>\n",
              "      <th>IMC</th>\n",
              "      <th>FunciónPedigríDeDiabetes</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Resultad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6fa73d6-fc16-48b3-92f5-824d9b6eaf50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6fa73d6-fc16-48b3-92f5-824d9b6eaf50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6fa73d6-fc16-48b3-92f5-824d9b6eaf50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53af2012-d6fa-417c-98ad-201c02e8658f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53af2012-d6fa-417c-98ad-201c02e8658f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53af2012-d6fa-417c-98ad-201c02e8658f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Embarazos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucosa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Presi\\u00f3nArterial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GrosorDeLaPiel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulina\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IMC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Funci\\u00f3nPedigr\\u00edDeDiabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resultad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocesamiento de los datos: En este paso, manejamos valores faltantes, convertimos las columnas a tipos adecuados (si es necesario) y dividimos los datos en características (X) y la etiqueta objetivo (Y)."
      ],
      "metadata": {
        "id": "9u2-P39u1yYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar valores nulos por la media de la columna\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "U1FZpqYZ42C-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar valores nulos (si los hubiera) por la media de la columna o eliminar las filas con nulos\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Dividir los datos en características (X) y la variable objetivo (Y)\n",
        "X = df.drop('Resultad', axis=1)  # 'Resultad' es la columna objetivo (0 o 1)\n",
        "y = df['Resultad']  # Etiqueta: 0 = no tiene diabetes, 1 = tiene diabetes"
      ],
      "metadata": {
        "id": "Z_euqRHy132H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividir los datos en conjuntos de entrenamiento y prueba: Separamos el conjunto de datos en un 80% para entrenamiento y un 20% para prueba utilizando train_test_split."
      ],
      "metadata": {
        "id": "kFflio8o467c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "otZOEkFA47Ei"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Definir el modelo XGBoost y aplicar Pipeline**\n",
        "\n",
        "Para asegurarnos de que el proceso sea más estructurado, usaremos un Pipeline para incluir el escalado de los datos y el modelo XGBoost:\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "URdAaH_e4-3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un pipeline con el escalado de características y XGBoost\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Normalizar las características\n",
        "    ('xgboost', xgb.XGBClassifier(random_state=42))  # Modelo XGBoost\n",
        "])\n"
      ],
      "metadata": {
        "id": "fPtu5whU5Bjf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los parámetros para generacion de los diferentes modelos"
      ],
      "metadata": {
        "id": "P1ZTjQvp5FNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los parámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    'xgboost__max_depth': [3, 5, 7],  # Profundidad máxima de los árboles\n",
        "    'xgboost__learning_rate': [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
        "    'xgboost__n_estimators': [50, 100, 200],  # Número de estimadores\n",
        "    'xgboost__subsample': [0.8, 1.0],  # Proporción de muestras usadas para entrenar cada árbol\n",
        "    'xgboost__colsample_bytree': [0.8, 1.0]  # Proporción de características usadas por árbol\n",
        "}"
      ],
      "metadata": {
        "id": "cPLHL_yx5FVw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizar la búsqueda de hiperparámetros con GridSearchCV**\n",
        "\n",
        "Utilizamos GridSearchCV para encontrar la mejor combinación de hiperparámetros para el modelo de XGBoost:"
      ],
      "metadata": {
        "id": "F_HApChM5Gyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar GridSearchCV con el pipeline y el parámetro grid\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Entrenar el modelo utilizando GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mejor modelo encontrado\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(\"Mejores hiperparámetros encontrados por GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FZIS6b75Xbk",
        "outputId": "ad86719c-77d4-49b8-f2b2-5e84cfcae2a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Mejores hiperparámetros encontrados por GridSearchCV:\n",
            "{'xgboost__colsample_bytree': 1.0, 'xgboost__learning_rate': 0.1, 'xgboost__max_depth': 3, 'xgboost__n_estimators': 50, 'xgboost__subsample': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluar el modelo**}\n",
        "\n",
        "Una vez que tenemos el mejor modelo, evaluamos su rendimiento en el conjunto de prueba:"
      ],
      "metadata": {
        "id": "7DDBAb0b5kJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir los resultados en el conjunto de prueba\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"\\nAccuracy del mejor modelo:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nReporte de clasificación del mejor modelo:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j_rGxCi5kVi",
        "outputId": "68f33c11-46a4-444e-ba5a-da69e4b1bd1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy del mejor modelo: 0.7467532467532467\n",
            "\n",
            "Reporte de clasificación del mejor modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.80        99\n",
            "           1       0.64      0.65      0.65        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.72      0.73      0.73       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpCNfaqL6foP",
        "outputId": "8306f300-a395-46e3-93c2-91fd6e9588b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Embarazos', 'Glucosa', 'PresiónArterial', 'GrosorDeLaPiel', 'Insulina',\n",
              "       'IMC', 'FunciónPedigríDeDiabetes', 'Edad'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo de predicción con nuevos datos**\n",
        "\n",
        "Si queremos realizar una predicción con nuevos datos, podemos hacerlo con el modelo entrenado. A continuación te muestro cómo hacerlo:"
      ],
      "metadata": {
        "id": "NvaNOVJX5wbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que tenemos un nuevo dato\n",
        "nuevo_dato = pd.DataFrame(np.array([[6, 148, 72, 35, 0, 33.6, 0.627, 50]]),columns=['Embarazos', 'Glucosa', 'PresiónArterial', 'GrosorDeLaPiel', 'Insulina','IMC', 'FunciónPedigríDeDiabetes', 'Edad'])  # Nuevo dato (con 8 características)\n",
        "\n",
        "# Realizar la predicción con el modelo entrenado\n",
        "prediccion = best_model.predict(nuevo_dato)\n",
        "\n",
        "# Mostrar la predicción\n",
        "if prediccion == 0:\n",
        "    print(\"\\nEl modelo predice que el paciente NO tiene diabetes.\")\n",
        "else:\n",
        "    print(\"\\nEl modelo predice que el paciente TIENE diabetes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QTnWGPc5wlb",
        "outputId": "25578532-037d-4e7e-aab5-72a4542f3134"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El modelo predice que el paciente TIENE diabetes.\n"
          ]
        }
      ]
    }
  ]
}